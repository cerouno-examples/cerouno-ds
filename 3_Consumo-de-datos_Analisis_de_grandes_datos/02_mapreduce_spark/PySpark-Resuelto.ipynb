{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programando con Python Spark (PySpark)\n",
    "\n",
    "Recordando:\n",
    "- El driver program accesa al ambiente de Spark mediante un objeto SparkContext\n",
    "- El tipo de dato y concepto clave en Spark es el dataset llamados RDD\n",
    "- Cargamos datos en un RDD y hacemos operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Â¡Nuestro primer programa!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/apache-spark/spark/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(master = \"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD\n",
    "\n",
    "**R**esilient **D**istributed **D**ateset (**RDD**)\n",
    "\n",
    "Recordando y agregando:\n",
    "- Contiene **Datos distribuidos** mediante **particiones** (de Workers)\n",
    "- Habilita **operaciones** para su **ejecuciÃ³n en paralelo**\n",
    "- Son **inmutables**\n",
    "- **En caso de pÃ©rdida, la computaciÃ³n ejecutada se re-ejecuta**\n",
    "\n",
    "\n",
    "Tres maneras de crear RDDs:\n",
    "\n",
    "- Mediante un dataset externo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribuyendo una colecciÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transformando un RDD existente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operaciones sobre RDDs\n",
    "\n",
    "#### Transformaciones\n",
    "\n",
    "Crean un nuevo RDD a partir de otro previo.\n",
    "\n",
    "P. ej.:\n",
    "*map()*\n",
    "\n",
    "\n",
    "#### Acciones\n",
    "\n",
    "Corre/ejecuta/computa un resultado basado en un RDD existente.\n",
    "\n",
    "P. ej.:\n",
    "*count()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProgramaciÃ³n Funcional con Python\n",
    "\n",
    "- Muchas transformaciones y algunas acciones esperan una funciÃ³n\n",
    "- En algunos casos, pueden ser funciones para operaciones mÃ¡s complejas\n",
    "- Para funciones simples, una expresiÃ³n lambda es conveniente:\n",
    "```python\n",
    ">>> lambda line: â€œPythonâ€ in line\n",
    "```\n",
    "\n",
    "\n",
    "### map()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Toma un valor, crea un nuevo valor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.map(lambda x: x * 2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter()\n",
    "\n",
    "- Lee un elemento a la vez\n",
    "- Evalua cada elemento\n",
    "- Regresa los elementos que pasan el filtro  (filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BBB = rdd.filter(lambda x: x % 2 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BBB.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.filter(lambda x: x % 2 == 0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatMap()\n",
    "\n",
    "Produce multiples elementos por cada elemento de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.map(lambda x: [x, x * 2]).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.flatMap(lambda x: [x, x * 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations are lazy!\n",
    "## Featuring: Lazy evaluation!! ðŸ”¥ðŸ™ˆ\n",
    "\n",
    "[Haskell Lazy Evaluation](https://wiki.haskell.org/Lazy_evaluation):\n",
    "\n",
    ">Lazy evaluation is a method to evaluate a Haskell program. It means that expressions are not evaluated when they are bound to variables, but their evaluation is deferred until their results are needed by other computations. In consequence, arguments are not evaluated before they are passed to a function, but only when their values are actually used. \n",
    "\n",
    "[The Incomplete Guide to Lazy Evaluation (in Haskell)](https://hackhands.com/guide-lazy-evaluation-haskell/):\n",
    "\n",
    "> Originally, I wanted to write a complete guide to lazy evaluation, but then.\n",
    "\n",
    ">Lazy evaluation is the most widely used method for executing Haskell program code on a computer. It determines the time and memory usage of Haskell programs, and it allows new and powerful ways to write modular code. To make full use of purely functional programming, a good understanding of lazy evaluation is very helpful.\n",
    "\n",
    "\n",
    "Un RDD solo es ejecutado cuando las acciones corren sobre el mismo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)\n",
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al usar la evaluaciÃ³n floja, Spark puede contener en memoria RDD que se procesa unicamente cuando se le requiere. Sin la necesidad de cargar a memoria todas las lineas conteniendo \"Python\".\n",
    "\n",
    "\n",
    "ðŸ’»ðŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acciones\n",
    "\n",
    "- Las acciones causan transformaciones para ser almacenadas en RDDs nuevos\n",
    "- TambiÃ©n regresan resultados a ambas partes: el *driver* o un almacenamiento externo\n",
    "- Los RDDs son re-calculados por cada acciÃ³n que se les ejecuta\n",
    "- Pueden ser almacenados para un uso posterior: `rdd.persist()`\n",
    "\n",
    "### count()\n",
    "\n",
    "Obtiene las instancias en el RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collect()\n",
    "- `collect()` recupera el RDD completo ðŸš’\n",
    "- Ãštil para inspeccionar datasets pequeÃ±os de manera local y para unit-testing\n",
    "- **LOS RESULTADOS DEBEN CABER EN LA MEMORIA DEL EQUIPO LOCAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.takeOrdered(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### take(), takeSample(), first(), top(), takeOrdered() \n",
    "\n",
    "- ```take(n)``` regresa los primeros *n* elementos de un RDD\n",
    "- ```take(n)``` puede obtener resultados sezgados. Su uso es adecuado solo para pruebas o debugging\n",
    "- ```takeSample()``` como el nombre lo indica, es el mÃ¡s adecuado para tomar una muesta del dataset\n",
    "- ```first(n)``` al igual que ```take(n)```, obtiene los primeros *n* elementos de un RDD\n",
    "- ```top(), takeOrdered()``` como mÃ©todos mÃ¡s formales para obtener elementos ordenados de un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### takeOrdered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([5, 1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.takeOrdered(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.takeOrdered(4, lambda n: -n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reduce()\n",
    "Toma dos elementos del mismo tipo y regresa un nuevo elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdd.reduce(lambda x, y:  x*y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia\n",
    "- Spark re-calcula los RDDs cada vez que se llama a una acciÃ³n:\n",
    "    - Esto puede ser caro y tambiÃ©n causar un trÃ¡fico innecesario desde el disco (lectura)\n",
    "- Podemos evitar esto almacenando datos en cachÃ© con ```persist()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Causa a Spark el recargar la variable \"lineas\" desde el disco ðŸ™Š\n",
    "%time lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando persistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas.persist() # Ahora, este RDD se mantiene en RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineasPython =  lineas.filter(lambda line :  \"Python\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Spark no volverÃ¡ a hacer el cÃ³mputo para \"lineas\" cada vez que es usado\n",
    "%time lineasPython.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un Pipeline de operaciones para RDDs\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> lineas.map(...).filter(...).count(...)\n",
    "\n",
    "\n",
    "\n",
    ">>> lineas = sc.textFile(\"README.md\")\n",
    ">>> (lineas\n",
    "     .map(...)\n",
    "     .filter(...)\n",
    "     .count(...))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas = sc.textFile(\"README.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineas.filter(lambda line :  \"Python\" in line).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 01: Crear un nuevo RDD con la cadena \"Hola Spark\" e imprimirla en pantalla al obtener el primer elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 02: Completar el siguiente bloque de cÃ³digo, para usar el archivo README.md e imprimir el numero de lineas y el conteo de palabras en el archivo\n",
    "\n",
    "```python\n",
    "\n",
    "# Crear un RDD a partir de un dataset\n",
    "readme_rdd =  \n",
    "# Imprimir en pantalla el num. de lineas del RDD\n",
    "print('Conteo de lineas: ')\n",
    "print()\n",
    "print('Conteo de palabras: ')\n",
    "palabras_lista = readme_rdd.flatMap(lambda linea: linea.split(\" \")) \\\n",
    "                            . # map\n",
    "                            .reduceByKey(lambda a, b: a + b) \\\n",
    "                            . # collect\n",
    "  print(palabras_lista)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Soluciones:\n",
    "\n",
    "#### Ejercicio 01\n",
    "```python\n",
    "hola_spark_rdd = sc.parallelize('Hola Spark')\n",
    "print(hola_spark_rdd.take(1))\n",
    "print(hola_spark_rdd.collect())\n",
    "\n",
    ">>> ['H']\n",
    ">>> ['H', 'o', 'l', 'a', ' ', 'S', 'p', 'a', 'r', 'k']\n",
    "```\n",
    "\n",
    "\n",
    "#### Ejercicio 02: reduceByKey() y collect()\n",
    "```python\n",
    "readme_rdd = sc.textFile('README.md')\n",
    "print('Conteo de lineas: ')\n",
    "print(readme_rdd.count())\n",
    "print('Conteo de palabras: ')\n",
    "palabras_lista = readme_rdd.flatMap(lambda linea: linea.split(\" \")) \\\n",
    "                            .map(lambda palabra: (palabra, 1)) \\\n",
    "                            .reduceByKey(lambda a, b: a + b) \\\n",
    "                            .collect()\n",
    "  print(palabras_lista)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word count con otro dataset y takeOrdered\n",
    "\n",
    "Referencia:\n",
    "```python\n",
    "Sort by keys (ascending):\n",
    "\n",
    ">>> RDD.takeOrdered(5, key = lambda x: x[0])\n",
    "\n",
    "Sort by keys (descending):\n",
    "\n",
    ">>> RDD.takeOrdered(5, key = lambda x: -x[0])\n",
    "\n",
    "Sort by values (ascending):\n",
    "\n",
    ">>> RDD.takeOrdered(5, key = lambda x: x[1])\n",
    "\n",
    "Sort by values (descending):\n",
    "\n",
    ">>> RDD.takeOrdered(5, key = lambda x: -x[1])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://www.gutenberg.org/files/74/74-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
