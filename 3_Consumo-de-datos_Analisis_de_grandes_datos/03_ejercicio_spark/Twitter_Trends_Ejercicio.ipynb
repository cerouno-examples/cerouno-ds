{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending Topics de Twitter con Spark Streaming\n",
    "\n",
    "\n",
    "\n",
    "- Este código no tiene la calidad requerida para sistemas en producción\n",
    "- El Broker de Twitter (*read.py*) usa la librería *socketstream* y queda a la escucha en un socket TCP (como servidor). El script a su vez está filtrando los tweets provenientes de la Streaming API de Twitter: https://dev.twitter.com/streaming/overview\n",
    "- A partir de este momento, el broker puede ser ejecutado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencias y configuración de contextos\n",
    "\n",
    "Cargar las librerías para el contexto: de Spark, SQL y Streaming. Así como otras dependencias del ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "from collections import namedtuple\n",
    "# Namedtuple: https://pymotw.com/2/collections/namedtuple.html, http://stackoverflow.com/questions/2970608/what-are-named-tuples-in-python\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear el contexto de Streaming. Con la configuración: \"TwitterTrend\" como nombre del programa, 10 segundos como intervalo para batch y dos hilos de ejecución.\n",
    "\n",
    "De igual manera, crear la instancia del contexto de SQL en Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contexto de Spark\n",
    "sc = SparkContext(\"local[2]\", \"TwitterFollower\")\n",
    "\n",
    "# Contexto de Spark Streaming\n",
    "ssc = StreamingContext(sc, 10)\n",
    "\n",
    "# Contexto de SQL\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instanciados los contextos, nos conectamos a la fuente de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Especificar fuente de datos: \n",
    "https://spark.apache.org/docs/latest/api/python/pyspark.streaming.html#pyspark.streaming.StreamingContext.socketTextStream\n",
    "\n",
    "Hostname: localhost\n",
    "Puerto: 5555\n",
    "'''\n",
    "\n",
    "\n",
    "socket_stream = ssc.socketTextStream(\"localhost\", 5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soporte de Window Operations y tuplas para conteo de etiquetas\n",
    "\n",
    "Creamos una ventana de tiempo.\n",
    "\n",
    "El RDD obtenido del DStream se creará cada 10 segundos, pero los datos que estarán en el RDD serán por los últimos 20 segundos.\n",
    "\n",
    "[Spark Streaming: Window Operations](https://spark.apache.org/docs/latest/streaming-programming-guide.html#window-operations)\n",
    "\n",
    "\n",
    "![](https://spark.apache.org/docs/latest/img/streaming-dstream-window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = socket_stream.window( 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un objeto namedtuple para almacenar las etiquetas y sus conteos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = (\"tag\", \"count\" )\n",
    "Tweet = namedtuple( 'Tweet', fields )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesar el flujo de datos\n",
    "\n",
    "1. Cada tweet/mensaje que se recibe, será cortado en palabras (*flatMap()*),\n",
    "2. Por cada registro generado, se filtrarán  las palabras que empiezan con el simbolo **#**,\n",
    "3. Después se convertirán esos registros a minúsculas, \n",
    "4. Se ejecuta una acción de mapeo a (palabra, 1)\n",
    "5. Luego, se reducen los pares (llave, valor) y cuentan las ocurrencias de cada Hashtag (palabra, n)\n",
    "6. El flujo se convierte en un Dataframe con las etiquetas resultantes y sus conteos.\n",
    "7. Entonces, se ordenan las etiquetas de forma descendente,\n",
    "8. Y se toman los primeros 10 registos,\n",
    "9. Finalmente, esos 10 registros se almacenan en una tabla temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.Tweet"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-89fb64fcec14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m ( lines.flatMap( lambda text: text.split( \" \" ) ) # 1\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#trump\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 2-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTweet\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# 5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lines' is not defined"
     ]
    }
   ],
   "source": [
    "( lines.flatMap( lambda text: text.split( \" \" ) ) # 1\n",
    "  .filter( lambda word: word.lower().startswith(\"#trump\") ) # 2-3\n",
    "  .map( lambda word: ( word.lower(), 1 ) ) # 4 \n",
    "  .reduceByKey( lambda a, b: a + b ) # 5\n",
    "  .map( lambda rec: Tweet( rec[0], rec[1] ) ) # 5,\n",
    "  .foreachRDD( lambda rdd: rdd.toDF().sort(desc(\"count\")).limit(10).registerTempTable(\"tweets\") ) ) # 6 -7 -8-9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iniciar el proceso de Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lazy evaluation\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql(\"SELECT tag, count FROM tweets\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graficar las tendencias\n",
    "\n",
    "Podemos cambiar los valores de time.sleep() junto con la operación en ventana de tiempo para actualizaciones más cortas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar el siguiente código\n",
    "# Pista 1: Spark SQL\n",
    "# Pista 2: Investigar como hacer plots con seaborn\n",
    "\n",
    "# Aqui hacemos set de seaborn, para que establezca las paletas de colores\n",
    "for i in range(0,1000):\n",
    "  time.sleep( 20 )\n",
    "  top_10_tweets = sqlContext.sql( '???' ) # Seleccionar las columnas tag, count de la tabla tweets\n",
    "  top_10_df = top_10_tweets.toPandas()\n",
    "  display.clear_output(wait=True)\n",
    "  xx.plt   # seaborn vs matplotlib\n",
    "  sn.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "  xx.plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.set()\n",
    "\n",
    "for i in range(0,1000):\n",
    "  time.sleep( 2 )\n",
    "  top_10_tweets = sqlContext.sql( 'Select tag, count from tweets' )\n",
    "  top_10_df = top_10_tweets.toPandas()\n",
    "  display.clear_output(wait=True)\n",
    "  plt.figure( figsize = ( 10, 8 ) )\n",
    "  sn.barplot( x=\"count\", y=\"tag\", data=top_10_df)\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
